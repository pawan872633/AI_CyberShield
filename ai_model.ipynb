{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ec204a-9667-422c-b890-13244a7e1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded Successfully!\n",
      "src_ip                   int64\n",
      "dst_ip                   int64\n",
      "src_port                 int64\n",
      "dst_port                 int64\n",
      "protocol                object\n",
      "packet_size              int64\n",
      "connection_duration    float64\n",
      "attack_type             object\n",
      "dtype: object\n",
      "   src_ip  dst_ip  src_port  dst_port protocol  packet_size  \\\n",
      "0     103     157     63576     59183     ICMP          931   \n",
      "1     180     141     55563     27765      UDP          461   \n",
      "2      93      46     12942     21628     ICMP         1225   \n",
      "3      15      35     62010     39311     ICMP          738   \n",
      "4     107     253     54169     56089      UDP          450   \n",
      "\n",
      "   connection_duration attack_type  \n",
      "0             8.145865      normal  \n",
      "1             7.097695      normal  \n",
      "2             9.675910         u2r  \n",
      "3             8.283855         dos  \n",
      "4             9.040628      normal  \n",
      "‚úÖ Protocol Encoder Saved Successfully!\n",
      "‚úÖ Attack Type Encoder Saved Successfully!\n",
      "üîç X shape: (1000, 7)\n",
      "üîç y shape: (1000,)\n",
      "‚úÖ X_train shape: (800, 7)\n",
      "‚úÖ X_test shape: (200, 7)\n",
      "‚úÖ y_train shape: (800,)\n",
      "‚úÖ y_test shape: (200,)\n",
      "üîç Class Distribution After SMOTE: Counter({3: 188, 2: 188, 4: 188, 1: 188, 0: 188})\n",
      "‚úÖ Scaler Saved Successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pawan\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AI Model Trained & Saved Successfully! üöÄ\n",
      "‚≠ê src_ip: 0.1489\n",
      "‚≠ê dst_ip: 0.1507\n",
      "‚≠ê src_port: 0.1714\n",
      "‚≠ê dst_port: 0.1689\n",
      "‚≠ê protocol: 0.0462\n",
      "‚≠ê packet_size: 0.1612\n",
      "‚≠ê connection_duration: 0.1526\n",
      "‚úÖ Model Trained with 7 Features\n",
      "üîç New Prediction: [0]\n",
      "üîç Decoded Prediction: ['dos']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# ‚úÖ Load Dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"dataset/intrusion_data.csv\")  # üîπ Ensure correct path\n",
    "    print(\"‚úÖ Dataset Loaded Successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Dataset File Not Found! Check Path.\")\n",
    "    exit()\n",
    "\n",
    "# ‚úÖ Ensure Required Columns Exist\n",
    "required_columns = [\"src_ip\", \"dst_ip\", \"src_port\", \"dst_port\", \"protocol\", \"packet_size\", \"connection_duration\", \"attack_type\"]\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"‚ùå Error: Missing columns in dataset -> {missing_columns}\")\n",
    "    exit()\n",
    "\n",
    "# ‚úÖ Data Type Check\n",
    "print(df.dtypes)\n",
    "\n",
    "# ‚úÖ Preview First 5 Rows\n",
    "print(df.head())\n",
    "\n",
    "# ‚úÖ Label Encoding for 'protocol'\n",
    "protocol_encoder = LabelEncoder()\n",
    "df[\"protocol\"] = protocol_encoder.fit_transform(df[\"protocol\"])\n",
    "with open(\"protocol_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(protocol_encoder, f)\n",
    "print(\"‚úÖ Protocol Encoder Saved Successfully!\")\n",
    "\n",
    "# ‚úÖ Label Encoding for 'attack_type'\n",
    "attack_encoder = LabelEncoder()\n",
    "df[\"attack_type\"] = attack_encoder.fit_transform(df[\"attack_type\"])\n",
    "with open(\"attack_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(attack_encoder, f)\n",
    "print(\"‚úÖ Attack Type Encoder Saved Successfully!\")\n",
    "\n",
    "# ‚úÖ Feature Selection\n",
    "X = df.drop(columns=[\"attack_type\"])\n",
    "y = df[\"attack_type\"]\n",
    "\n",
    "# ‚úÖ Debugging: Shape Check\n",
    "print(\"üîç X shape:\", X.shape)\n",
    "print(\"üîç y shape:\", y.shape)\n",
    "\n",
    "# ‚úÖ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"‚úÖ X_train shape:\", X_train.shape)\n",
    "print(\"‚úÖ X_test shape:\", X_test.shape)\n",
    "print(\"‚úÖ y_train shape:\", y_train.shape)\n",
    "print(\"‚úÖ y_test shape:\", y_test.shape)\n",
    "\n",
    "# ‚úÖ Handle Data Imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"üîç Class Distribution After SMOTE:\", Counter(y_resampled))\n",
    "\n",
    "# ‚úÖ Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"‚úÖ Scaler Saved Successfully!\")\n",
    "\n",
    "# ‚úÖ Train Model (Hyperparameter Tuning for Accuracy)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=20, \n",
    "    min_samples_split=5, \n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_resampled)\n",
    "\n",
    "# ‚úÖ Save Model\n",
    "joblib.dump(model, \"best_model.pkl\")\n",
    "print(\"‚úÖ AI Model Trained & Saved Successfully! üöÄ\")\n",
    "\n",
    "# ‚úÖ Feature Importance Debugging\n",
    "importances = model.feature_importances_\n",
    "for feature, importance in zip(X.columns, importances):\n",
    "    print(f\"‚≠ê {feature}: {importance:.4f}\")\n",
    "\n",
    "# ‚úÖ Debug: Ensure Feature Count Matches\n",
    "print(f\"‚úÖ Model Trained with {X_train.shape[1]} Features\")\n",
    "\n",
    "# ‚úÖ Load Model & Perform Prediction\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "model = joblib.load(\"best_model.pkl\")\n",
    "\n",
    "# ‚úÖ New Test Sample (Ensure Feature Order Matches Training Data)\n",
    "sample = np.array([[150, 130, 35000, 34500, 0, 800, 7]])\n",
    "sample_df = pd.DataFrame(sample, columns=X.columns)  # Match Feature Names\n",
    "scaled_sample = scaler.transform(sample_df)\n",
    "prediction = model.predict(scaled_sample)\n",
    "\n",
    "# ‚úÖ Decode Prediction\n",
    "decoded_prediction = attack_encoder.inverse_transform(prediction)\n",
    "print(\"üîç New Prediction:\", prediction)\n",
    "print(\"üîç Decoded Prediction:\", decoded_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0b344-d01e-4e21-9dc5-18b3eb057ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
